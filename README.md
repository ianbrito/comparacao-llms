# Comparação de LLMs

### Ambiente

 - python: `3.10.12`
 - Docker: `version 28.0.0, build f9ced58`
 - Ollama: `0.5.12`
> O ollama está sendo escutado via docker

Modelos:

- gemma:latest    
- llama3.2:3b     
- mistral:latest  
- deepseek-r1:1.5b


### Relatório

[Relatório Comparação de Modelos de Linguagem](https://drive.google.com/file/d/1AZQ7iNepVij4rbiid_-eGhQMlnU-GVwi/view?usp=sharing)